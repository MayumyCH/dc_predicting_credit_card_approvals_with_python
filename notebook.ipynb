{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.7","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"notebook.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"GAsXeGFzkycG"},"source":["# PROYECTO: Predicting Credit Card Approvals\n","_Cree un modelo de aprendizaje automático para predecir si se aprobará una solicitud de tarjeta de crédito._\n","\n","> ****\n","\n","**Project Description**\n","\n","Los bancos comerciales reciben muchas solicitudes de tarjetas de crédito. Muchos de ellos son rechazados por muchas razones, como saldos elevados de préstamos, bajos niveles de ingresos o demasiadas consultas sobre el informe crediticio de una persona, por ejemplo. El análisis manual de estas aplicaciones es mundano, propenso a errores y requiere mucho tiempo (¡y el tiempo es dinero!). Afortunadamente, esta tarea se puede automatizar con el poder del aprendizaje automático y casi todos los bancos comerciales lo hacen hoy en día. En este proyecto, creará un predictor automático de aprobación de tarjetas de crédito utilizando técnicas de aprendizaje automático, tal como lo hacen los bancos reales.\n","\n","El conjunto de datos utilizado en este proyecto es el [conjunto de datos de aprobación de tarjetas de crédito](http://archive.ics.uci.edu/ml/datasets/credit+approval) del Repositorio de aprendizaje automático de [UCI](http://archive.ics.uci.edu/ml/index.php).\n"]},{"cell_type":"markdown","metadata":{"id":"BOVNISPnlz8N"},"source":["> ***\n","\n","**Project Tasks**\n","1. Credit card applications\n","2. Inspecting the applications\n","3. Handling the missing values (part i)\n","4. Handling the missing values (part ii)\n","5. Handling the missing values (part iii)\n","6. Preprocessing the data (part i)\n","7. Splitting the dataset into train and test sets\n","8. Preprocessing the data (part ii)\n","9. Fitting a logistic regression model to the train set\n","10. Making predictions and evaluating performance\n","11. Grid searching and making the model perform better\n","12. Finding the best performing model\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"jNAuGlFErdYY"},"source":["Recursos importantes:\n","\n","\n","*   [Pandas Cheatsheet](https://www.datacamp.com/community/blog/python-pandas-cheat-sheet)\n","*   [NumPy Cheat Sheet](https://www.datacamp.com/community/blog/python-numpy-cheat-sheet)\n","* [Preprocessing in Data Science (Part 3)](https://www.datacamp.com/community/tutorials/preprocessing-in-data-science-part-3-scaling-synthesized-data)\n","* [Preprocessing in Data Science (Part 2)](https://www.datacamp.com/community/tutorials/preprocessing-in-data-science-part-2-centering-scaling-and-logistic-regression)\n","* [Preprocessing in Data Science (Part 1)](https://www.datacamp.com/community/tutorials/preprocessing-in-data-science-part-1-centering-scaling-and-knn)\n","* Google's [Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/)\n","\n"]},{"cell_type":"markdown","metadata":{"dc":{"key":"3"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"],"id":"JfRv5QqEkYaX"},"source":["## 1. Credit card applications\n","\n","**(Solicitudes de tarjetas de crédito)**\n","\n","<p> <img src = \"https://assets.datacamp.com/production/project_558/img/credit_card.jpg\" alt = \"Tarjeta de crédito en mano\" height = 200px> </p>\n","<p> Usaremos el <a href=\"http://archive.ics.uci.edu/ml/datasets/credit+approval\"> conjunto de datos de aprobación de tarjetas de crédito </a> del Repositorio de aprendizaje automático de UCI. La estructura de este cuaderno es la siguiente: </p>\n","<ul>\n","<li> Primero, comenzaremos cargando y viendo el conjunto de datos. </li>\n","<li> Veremos que el conjunto de datos tiene una combinación de características numéricas y no numéricas, que contiene valores de diferentes rangos, además de que contiene una cantidad de entradas faltantes. </li>\n","<li> Tendremos que preprocesar el conjunto de datos para asegurarnos de que el modelo de aprendizaje automático que elegimos pueda hacer buenas predicciones. </li>\n","<li> Una vez que nuestros datos estén en buena forma, haremos un análisis de datos exploratorio para construir nuestras intuiciones. </li>\n","<li> Por último, crearemos un modelo de aprendizaje automático que puede predecir si se aceptará la solicitud de una persona para obtener una tarjeta de crédito. </li>\n","</ul>\n","<p> Primero, cargar y ver el conjunto de datos. Descubrimos que, dado que estos datos son confidenciales, el contribuyente del conjunto de datos ha anonimizado los nombres de las funciones. </p>"]},{"cell_type":"code","metadata":{"dc":{"key":"3"},"tags":["sample_code"],"trusted":false,"colab":{"base_uri":"https://localhost:8080/","height":203},"id":"4sucjijekYab","executionInfo":{"status":"ok","timestamp":1633660303457,"user_tz":300,"elapsed":212,"user":{"displayName":"heydy carrasco huaccha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGyezGgm9Px4LBw_sc7MFWfjUVhWWsvnAz1Ttg=s64","userId":"00007591481982700116"}},"outputId":"d48f292f-f446-495b-8cad-ac9f44bd8b90"},"source":["# Importando modulos\n","import pandas as pd\n","import numpy as np\n","\n","# Cargar dataset\n","cc_apps = pd.read_csv('https://raw.githubusercontent.com/MayumyCH/dc_predicting_credit_card_approvals_with_python/main/dataset/cc_approvals.data',header=None)\n","\n","cc_apps.head(5)"],"execution_count":99,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>b</td>\n","      <td>30.83</td>\n","      <td>0.000</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>w</td>\n","      <td>v</td>\n","      <td>1.25</td>\n","      <td>t</td>\n","      <td>t</td>\n","      <td>1</td>\n","      <td>f</td>\n","      <td>g</td>\n","      <td>00202</td>\n","      <td>0</td>\n","      <td>+</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>a</td>\n","      <td>58.67</td>\n","      <td>4.460</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>q</td>\n","      <td>h</td>\n","      <td>3.04</td>\n","      <td>t</td>\n","      <td>t</td>\n","      <td>6</td>\n","      <td>f</td>\n","      <td>g</td>\n","      <td>00043</td>\n","      <td>560</td>\n","      <td>+</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>a</td>\n","      <td>24.50</td>\n","      <td>0.500</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>q</td>\n","      <td>h</td>\n","      <td>1.50</td>\n","      <td>t</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>f</td>\n","      <td>g</td>\n","      <td>00280</td>\n","      <td>824</td>\n","      <td>+</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>b</td>\n","      <td>27.83</td>\n","      <td>1.540</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>w</td>\n","      <td>v</td>\n","      <td>3.75</td>\n","      <td>t</td>\n","      <td>t</td>\n","      <td>5</td>\n","      <td>t</td>\n","      <td>g</td>\n","      <td>00100</td>\n","      <td>3</td>\n","      <td>+</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>b</td>\n","      <td>20.17</td>\n","      <td>5.625</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>w</td>\n","      <td>v</td>\n","      <td>1.71</td>\n","      <td>t</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>f</td>\n","      <td>s</td>\n","      <td>00120</td>\n","      <td>0</td>\n","      <td>+</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14 15\n","0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  f  g  00202    0  +\n","1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g  00043  560  +\n","2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  00280  824  +\n","3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  00100    3  +\n","4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  00120    0  +"]},"metadata":{},"execution_count":99}]},{"cell_type":"markdown","metadata":{"dc":{"key":"10"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"],"id":"B1KKtsJrkYac"},"source":["## 2. Inspecting the applications\n","**(Inspección de las aplicaciones)**\n","<p> El resultado puede parecer un poco confuso a primera vista, pero intentemos descubrir las características más importantes de una aplicación de tarjeta de crédito. Las funciones de este conjunto de datos se han anonimizado para proteger la privacidad, pero <a href=\"http://rstudio-pubs-static.s3.amazonaws.com/73039_9946de135c0a49daa7a0a9eda4a67a72.html\"> este blog </a>  nos brinda una bonita buena descripción de las características probables. Las características probables en una aplicación de tarjeta de crédito típica son <code> Género </code>, <code> Edad </code>, <code> Debt </code>, <code> Married </code>, <code> BankCustomer </code>, <code> EducationLevel </code>, <code> Ethnicity </code>, <code> YearsEmployed </code>, <code> PriorDefault </code>, <code> Employed </code>, <code> CreditScore </code>, <code> DriversLicense </code>, <code> Citizen </code>, <code> ZipCode </code>, <code> Income </code> y finalmente el <code> ApprovalStatus </code>. Esto nos da un buen punto de partida y podemos mapear estas características con respecto a las columnas en la salida. </p>\n","<p> Como podemos ver en nuestro primer vistazo a los datos, el conjunto de datos tiene una combinación de características numéricas y no numéricas. Esto se puede solucionar con un poco de procesamiento previo, pero antes de hacerlo, aprendamos un poco más sobre el conjunto de datos para ver si hay otros problemas del conjunto de datos que deban solucionarse. </p>"]},{"cell_type":"code","metadata":{"dc":{"key":"10"},"tags":["sample_code"],"collapsed":true,"trusted":false,"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"bvTJmy0TkYac","executionInfo":{"status":"ok","timestamp":1633660303812,"user_tz":300,"elapsed":5,"user":{"displayName":"heydy carrasco huaccha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGyezGgm9Px4LBw_sc7MFWfjUVhWWsvnAz1Ttg=s64","userId":"00007591481982700116"}},"outputId":"5c64e363-c788-404a-897b-63f752d86e75"},"source":["# Imprimir resumen de estadísticas\n","cc_apps_description = cc_apps.describe()\n","print(cc_apps_description)\n","\n","print(\"\\n\")\n","\n","# Imprimir información de DataFrame\n","cc_apps_info = cc_apps.info()\n","print(cc_apps_info)\n","\n","print(\"\\n\")\n","\n","# Inspeccionar los valores faltantes en el conjunto de datos\n","cc_apps.tail(17)"],"execution_count":100,"outputs":[{"output_type":"stream","name":"stdout","text":["               2           7          10             14\n","count  690.000000  690.000000  690.00000     690.000000\n","mean     4.758725    2.223406    2.40000    1017.385507\n","std      4.978163    3.346513    4.86294    5210.102598\n","min      0.000000    0.000000    0.00000       0.000000\n","25%      1.000000    0.165000    0.00000       0.000000\n","50%      2.750000    1.000000    0.00000       5.000000\n","75%      7.207500    2.625000    3.00000     395.500000\n","max     28.000000   28.500000   67.00000  100000.000000\n","\n","\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 690 entries, 0 to 689\n","Data columns (total 16 columns):\n"," #   Column  Non-Null Count  Dtype  \n","---  ------  --------------  -----  \n"," 0   0       690 non-null    object \n"," 1   1       690 non-null    object \n"," 2   2       690 non-null    float64\n"," 3   3       690 non-null    object \n"," 4   4       690 non-null    object \n"," 5   5       690 non-null    object \n"," 6   6       690 non-null    object \n"," 7   7       690 non-null    float64\n"," 8   8       690 non-null    object \n"," 9   9       690 non-null    object \n"," 10  10      690 non-null    int64  \n"," 11  11      690 non-null    object \n"," 12  12      690 non-null    object \n"," 13  13      690 non-null    object \n"," 14  14      690 non-null    int64  \n"," 15  15      690 non-null    object \n","dtypes: float64(2), int64(2), object(12)\n","memory usage: 86.4+ KB\n","None\n","\n","\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>673</th>\n","      <td>?</td>\n","      <td>29.50</td>\n","      <td>2.000</td>\n","      <td>y</td>\n","      <td>p</td>\n","      <td>e</td>\n","      <td>h</td>\n","      <td>2.000</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>f</td>\n","      <td>g</td>\n","      <td>00256</td>\n","      <td>17</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>674</th>\n","      <td>a</td>\n","      <td>37.33</td>\n","      <td>2.500</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>i</td>\n","      <td>h</td>\n","      <td>0.210</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>f</td>\n","      <td>g</td>\n","      <td>00260</td>\n","      <td>246</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>675</th>\n","      <td>a</td>\n","      <td>41.58</td>\n","      <td>1.040</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>aa</td>\n","      <td>v</td>\n","      <td>0.665</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>f</td>\n","      <td>g</td>\n","      <td>00240</td>\n","      <td>237</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>676</th>\n","      <td>a</td>\n","      <td>30.58</td>\n","      <td>10.665</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>q</td>\n","      <td>h</td>\n","      <td>0.085</td>\n","      <td>f</td>\n","      <td>t</td>\n","      <td>12</td>\n","      <td>t</td>\n","      <td>g</td>\n","      <td>00129</td>\n","      <td>3</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>677</th>\n","      <td>b</td>\n","      <td>19.42</td>\n","      <td>7.250</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>m</td>\n","      <td>v</td>\n","      <td>0.040</td>\n","      <td>f</td>\n","      <td>t</td>\n","      <td>1</td>\n","      <td>f</td>\n","      <td>g</td>\n","      <td>00100</td>\n","      <td>1</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>678</th>\n","      <td>a</td>\n","      <td>17.92</td>\n","      <td>10.210</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>ff</td>\n","      <td>ff</td>\n","      <td>0.000</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>f</td>\n","      <td>g</td>\n","      <td>00000</td>\n","      <td>50</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>679</th>\n","      <td>a</td>\n","      <td>20.08</td>\n","      <td>1.250</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>c</td>\n","      <td>v</td>\n","      <td>0.000</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>f</td>\n","      <td>g</td>\n","      <td>00000</td>\n","      <td>0</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>680</th>\n","      <td>b</td>\n","      <td>19.50</td>\n","      <td>0.290</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>k</td>\n","      <td>v</td>\n","      <td>0.290</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>f</td>\n","      <td>g</td>\n","      <td>00280</td>\n","      <td>364</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>681</th>\n","      <td>b</td>\n","      <td>27.83</td>\n","      <td>1.000</td>\n","      <td>y</td>\n","      <td>p</td>\n","      <td>d</td>\n","      <td>h</td>\n","      <td>3.000</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>f</td>\n","      <td>g</td>\n","      <td>00176</td>\n","      <td>537</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>682</th>\n","      <td>b</td>\n","      <td>17.08</td>\n","      <td>3.290</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>i</td>\n","      <td>v</td>\n","      <td>0.335</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>t</td>\n","      <td>g</td>\n","      <td>00140</td>\n","      <td>2</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>683</th>\n","      <td>b</td>\n","      <td>36.42</td>\n","      <td>0.750</td>\n","      <td>y</td>\n","      <td>p</td>\n","      <td>d</td>\n","      <td>v</td>\n","      <td>0.585</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>f</td>\n","      <td>g</td>\n","      <td>00240</td>\n","      <td>3</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>684</th>\n","      <td>b</td>\n","      <td>40.58</td>\n","      <td>3.290</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>m</td>\n","      <td>v</td>\n","      <td>3.500</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>t</td>\n","      <td>s</td>\n","      <td>00400</td>\n","      <td>0</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>685</th>\n","      <td>b</td>\n","      <td>21.08</td>\n","      <td>10.085</td>\n","      <td>y</td>\n","      <td>p</td>\n","      <td>e</td>\n","      <td>h</td>\n","      <td>1.250</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>f</td>\n","      <td>g</td>\n","      <td>00260</td>\n","      <td>0</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>686</th>\n","      <td>a</td>\n","      <td>22.67</td>\n","      <td>0.750</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>c</td>\n","      <td>v</td>\n","      <td>2.000</td>\n","      <td>f</td>\n","      <td>t</td>\n","      <td>2</td>\n","      <td>t</td>\n","      <td>g</td>\n","      <td>00200</td>\n","      <td>394</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>687</th>\n","      <td>a</td>\n","      <td>25.25</td>\n","      <td>13.500</td>\n","      <td>y</td>\n","      <td>p</td>\n","      <td>ff</td>\n","      <td>ff</td>\n","      <td>2.000</td>\n","      <td>f</td>\n","      <td>t</td>\n","      <td>1</td>\n","      <td>t</td>\n","      <td>g</td>\n","      <td>00200</td>\n","      <td>1</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>688</th>\n","      <td>b</td>\n","      <td>17.92</td>\n","      <td>0.205</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>aa</td>\n","      <td>v</td>\n","      <td>0.040</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>f</td>\n","      <td>g</td>\n","      <td>00280</td>\n","      <td>750</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>689</th>\n","      <td>b</td>\n","      <td>35.00</td>\n","      <td>3.375</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>c</td>\n","      <td>h</td>\n","      <td>8.290</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>t</td>\n","      <td>g</td>\n","      <td>00000</td>\n","      <td>0</td>\n","      <td>-</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    0      1       2  3  4   5   6      7  8  9   10 11 12     13   14 15\n","673  ?  29.50   2.000  y  p   e   h  2.000  f  f   0  f  g  00256   17  -\n","674  a  37.33   2.500  u  g   i   h  0.210  f  f   0  f  g  00260  246  -\n","675  a  41.58   1.040  u  g  aa   v  0.665  f  f   0  f  g  00240  237  -\n","676  a  30.58  10.665  u  g   q   h  0.085  f  t  12  t  g  00129    3  -\n","677  b  19.42   7.250  u  g   m   v  0.040  f  t   1  f  g  00100    1  -\n","678  a  17.92  10.210  u  g  ff  ff  0.000  f  f   0  f  g  00000   50  -\n","679  a  20.08   1.250  u  g   c   v  0.000  f  f   0  f  g  00000    0  -\n","680  b  19.50   0.290  u  g   k   v  0.290  f  f   0  f  g  00280  364  -\n","681  b  27.83   1.000  y  p   d   h  3.000  f  f   0  f  g  00176  537  -\n","682  b  17.08   3.290  u  g   i   v  0.335  f  f   0  t  g  00140    2  -\n","683  b  36.42   0.750  y  p   d   v  0.585  f  f   0  f  g  00240    3  -\n","684  b  40.58   3.290  u  g   m   v  3.500  f  f   0  t  s  00400    0  -\n","685  b  21.08  10.085  y  p   e   h  1.250  f  f   0  f  g  00260    0  -\n","686  a  22.67   0.750  u  g   c   v  2.000  f  t   2  t  g  00200  394  -\n","687  a  25.25  13.500  y  p  ff  ff  2.000  f  t   1  t  g  00200    1  -\n","688  b  17.92   0.205  u  g  aa   v  0.040  f  f   0  f  g  00280  750  -\n","689  b  35.00   3.375  u  g   c   h  8.290  f  f   0  t  g  00000    0  -"]},"metadata":{},"execution_count":100}]},{"cell_type":"markdown","metadata":{"dc":{"key":"17"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"],"id":"BzeE9-zvkYac"},"source":["## 3. Handling the missing values (part i)\n","**(Manejo de los valores perdidos (parte i))**\n","<p> Hemos descubierto algunos problemas que afectarán el rendimiento de nuestros modelos de aprendizaje automático si no se modifican: </p>\n","<ul>\n","<li> Nuestro conjunto de datos contiene datos numéricos y no numéricos (específicamente datos que son de los tipos <code> float64 </code>, <code> int64 </code> y <code> object </code>). Específicamente, las características 2, 7, 10 y 14 contienen valores numéricos (de tipos float64, float64, int64 e int64 respectivamente) y todas las demás características contienen valores no numéricos. </li>\n","<li> El conjunto de datos también contiene valores de varios rangos. Algunas características tienen un rango de valores de 0 a 28, algunas tienen un rango de 2 a 67 y algunas tienen un rango de 1017 a 100000. Aparte de estas, podemos obtener información estadística útil (como <code> mean </code> , <code> max </code> y <code> min </code>) sobre las características que tienen valores numéricos. </li>\n","<li> Por último, el conjunto de datos tiene valores faltantes, de los que nos ocuparemos en esta tarea. Los valores faltantes en el conjunto de datos están etiquetados con \"?\", Que se puede ver en la salida de la última celda. </li>\n","</ul>\n","<p> Ahora, reemplacemos temporalmente estos signos de interrogación de valor que faltan por NaN. </p> "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":858},"id":"udMqk22YwvBE","executionInfo":{"status":"ok","timestamp":1633660304144,"user_tz":300,"elapsed":335,"user":{"displayName":"heydy carrasco huaccha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGyezGgm9Px4LBw_sc7MFWfjUVhWWsvnAz1Ttg=s64","userId":"00007591481982700116"}},"outputId":"5d378211-3773-4d8a-fed3-fb6507993c1a"},"source":["# Inspecciona los valores faltantes en el conjunto de datos\n","print(cc_apps.isnull().sum())\n","\n","# Reemplace el '?' Por NaN\n","cc_apps = cc_apps.replace('?',np.nan)\n","\n","# Inspeccione los valores perdidos nuevamente\n","cc_apps.tail(17)"],"execution_count":101,"outputs":[{"output_type":"stream","name":"stdout","text":["0     0\n","1     0\n","2     0\n","3     0\n","4     0\n","5     0\n","6     0\n","7     0\n","8     0\n","9     0\n","10    0\n","11    0\n","12    0\n","13    0\n","14    0\n","15    0\n","dtype: int64\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>673</th>\n","      <td>NaN</td>\n","      <td>29.50</td>\n","      <td>2.000</td>\n","      <td>y</td>\n","      <td>p</td>\n","      <td>e</td>\n","      <td>h</td>\n","      <td>2.000</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>f</td>\n","      <td>g</td>\n","      <td>00256</td>\n","      <td>17</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>674</th>\n","      <td>a</td>\n","      <td>37.33</td>\n","      <td>2.500</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>i</td>\n","      <td>h</td>\n","      <td>0.210</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>f</td>\n","      <td>g</td>\n","      <td>00260</td>\n","      <td>246</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>675</th>\n","      <td>a</td>\n","      <td>41.58</td>\n","      <td>1.040</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>aa</td>\n","      <td>v</td>\n","      <td>0.665</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>f</td>\n","      <td>g</td>\n","      <td>00240</td>\n","      <td>237</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>676</th>\n","      <td>a</td>\n","      <td>30.58</td>\n","      <td>10.665</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>q</td>\n","      <td>h</td>\n","      <td>0.085</td>\n","      <td>f</td>\n","      <td>t</td>\n","      <td>12</td>\n","      <td>t</td>\n","      <td>g</td>\n","      <td>00129</td>\n","      <td>3</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>677</th>\n","      <td>b</td>\n","      <td>19.42</td>\n","      <td>7.250</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>m</td>\n","      <td>v</td>\n","      <td>0.040</td>\n","      <td>f</td>\n","      <td>t</td>\n","      <td>1</td>\n","      <td>f</td>\n","      <td>g</td>\n","      <td>00100</td>\n","      <td>1</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>678</th>\n","      <td>a</td>\n","      <td>17.92</td>\n","      <td>10.210</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>ff</td>\n","      <td>ff</td>\n","      <td>0.000</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>f</td>\n","      <td>g</td>\n","      <td>00000</td>\n","      <td>50</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>679</th>\n","      <td>a</td>\n","      <td>20.08</td>\n","      <td>1.250</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>c</td>\n","      <td>v</td>\n","      <td>0.000</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>f</td>\n","      <td>g</td>\n","      <td>00000</td>\n","      <td>0</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>680</th>\n","      <td>b</td>\n","      <td>19.50</td>\n","      <td>0.290</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>k</td>\n","      <td>v</td>\n","      <td>0.290</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>f</td>\n","      <td>g</td>\n","      <td>00280</td>\n","      <td>364</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>681</th>\n","      <td>b</td>\n","      <td>27.83</td>\n","      <td>1.000</td>\n","      <td>y</td>\n","      <td>p</td>\n","      <td>d</td>\n","      <td>h</td>\n","      <td>3.000</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>f</td>\n","      <td>g</td>\n","      <td>00176</td>\n","      <td>537</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>682</th>\n","      <td>b</td>\n","      <td>17.08</td>\n","      <td>3.290</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>i</td>\n","      <td>v</td>\n","      <td>0.335</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>t</td>\n","      <td>g</td>\n","      <td>00140</td>\n","      <td>2</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>683</th>\n","      <td>b</td>\n","      <td>36.42</td>\n","      <td>0.750</td>\n","      <td>y</td>\n","      <td>p</td>\n","      <td>d</td>\n","      <td>v</td>\n","      <td>0.585</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>f</td>\n","      <td>g</td>\n","      <td>00240</td>\n","      <td>3</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>684</th>\n","      <td>b</td>\n","      <td>40.58</td>\n","      <td>3.290</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>m</td>\n","      <td>v</td>\n","      <td>3.500</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>t</td>\n","      <td>s</td>\n","      <td>00400</td>\n","      <td>0</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>685</th>\n","      <td>b</td>\n","      <td>21.08</td>\n","      <td>10.085</td>\n","      <td>y</td>\n","      <td>p</td>\n","      <td>e</td>\n","      <td>h</td>\n","      <td>1.250</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>f</td>\n","      <td>g</td>\n","      <td>00260</td>\n","      <td>0</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>686</th>\n","      <td>a</td>\n","      <td>22.67</td>\n","      <td>0.750</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>c</td>\n","      <td>v</td>\n","      <td>2.000</td>\n","      <td>f</td>\n","      <td>t</td>\n","      <td>2</td>\n","      <td>t</td>\n","      <td>g</td>\n","      <td>00200</td>\n","      <td>394</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>687</th>\n","      <td>a</td>\n","      <td>25.25</td>\n","      <td>13.500</td>\n","      <td>y</td>\n","      <td>p</td>\n","      <td>ff</td>\n","      <td>ff</td>\n","      <td>2.000</td>\n","      <td>f</td>\n","      <td>t</td>\n","      <td>1</td>\n","      <td>t</td>\n","      <td>g</td>\n","      <td>00200</td>\n","      <td>1</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>688</th>\n","      <td>b</td>\n","      <td>17.92</td>\n","      <td>0.205</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>aa</td>\n","      <td>v</td>\n","      <td>0.040</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>f</td>\n","      <td>g</td>\n","      <td>00280</td>\n","      <td>750</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>689</th>\n","      <td>b</td>\n","      <td>35.00</td>\n","      <td>3.375</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>c</td>\n","      <td>h</td>\n","      <td>8.290</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>t</td>\n","      <td>g</td>\n","      <td>00000</td>\n","      <td>0</td>\n","      <td>-</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      0      1       2  3  4   5   6      7  8  9   10 11 12     13   14 15\n","673  NaN  29.50   2.000  y  p   e   h  2.000  f  f   0  f  g  00256   17  -\n","674    a  37.33   2.500  u  g   i   h  0.210  f  f   0  f  g  00260  246  -\n","675    a  41.58   1.040  u  g  aa   v  0.665  f  f   0  f  g  00240  237  -\n","676    a  30.58  10.665  u  g   q   h  0.085  f  t  12  t  g  00129    3  -\n","677    b  19.42   7.250  u  g   m   v  0.040  f  t   1  f  g  00100    1  -\n","678    a  17.92  10.210  u  g  ff  ff  0.000  f  f   0  f  g  00000   50  -\n","679    a  20.08   1.250  u  g   c   v  0.000  f  f   0  f  g  00000    0  -\n","680    b  19.50   0.290  u  g   k   v  0.290  f  f   0  f  g  00280  364  -\n","681    b  27.83   1.000  y  p   d   h  3.000  f  f   0  f  g  00176  537  -\n","682    b  17.08   3.290  u  g   i   v  0.335  f  f   0  t  g  00140    2  -\n","683    b  36.42   0.750  y  p   d   v  0.585  f  f   0  f  g  00240    3  -\n","684    b  40.58   3.290  u  g   m   v  3.500  f  f   0  t  s  00400    0  -\n","685    b  21.08  10.085  y  p   e   h  1.250  f  f   0  f  g  00260    0  -\n","686    a  22.67   0.750  u  g   c   v  2.000  f  t   2  t  g  00200  394  -\n","687    a  25.25  13.500  y  p  ff  ff  2.000  f  t   1  t  g  00200    1  -\n","688    b  17.92   0.205  u  g  aa   v  0.040  f  f   0  f  g  00280  750  -\n","689    b  35.00   3.375  u  g   c   h  8.290  f  f   0  t  g  00000    0  -"]},"metadata":{},"execution_count":101}]},{"cell_type":"markdown","metadata":{"dc":{"key":"24"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"],"id":"-wVmfEsakYae"},"source":["## 4. Handling the missing values (part ii)\n","**(Manejo de los valores perdidos (parte ii))**\n","<p> Reemplazamos todos los signos de interrogación con NaN. Esto nos ayudará en el próximo tratamiento de valor perdido que realizaremos. </p>\n","<p> Una pregunta importante que se plantea aquí es <em> ¿por qué le damos tanta importancia a los valores perdidos </em>? ¿No se pueden simplemente ignorar? Ignorar los valores perdidos puede afectar en gran medida el rendimiento de un modelo de aprendizaje automático. Si bien ignora los valores faltantes, nuestro modelo de aprendizaje automático puede perder información sobre el conjunto de datos que puede ser útil para su entrenamiento. Entonces, hay muchos modelos que no pueden manejar valores perdidos implícitamente, como LDA. </p>\n","<p> Entonces, para evitar este problema, vamos a imputar los valores faltantes con una estrategia llamada <b>imputación media</b>. </p>"]},{"cell_type":"code","metadata":{"dc":{"key":"24"},"tags":["sample_code"],"collapsed":true,"trusted":false,"id":"Ro6e_TprkYae","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633660304145,"user_tz":300,"elapsed":9,"user":{"displayName":"heydy carrasco huaccha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGyezGgm9Px4LBw_sc7MFWfjUVhWWsvnAz1Ttg=s64","userId":"00007591481982700116"}},"outputId":"afb3b195-a321-45a2-99d4-83ebfb8e77b3"},"source":["# Imputar los valores perdidos con imputación media\n","cc_apps.fillna(cc_apps.mean(), inplace=True)\n","\n","# Cuente la cantidad de NaN en el conjunto de datos para verificar\n","print(cc_apps.isnull().sum())"],"execution_count":102,"outputs":[{"output_type":"stream","name":"stdout","text":["0     12\n","1     12\n","2      0\n","3      6\n","4      6\n","5      9\n","6      9\n","7      0\n","8      0\n","9      0\n","10     0\n","11     0\n","12     0\n","13    13\n","14     0\n","15     0\n","dtype: int64\n"]}]},{"cell_type":"markdown","metadata":{"dc":{"key":"31"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"],"id":"wani8WoLkYaf"},"source":["## 5. Handling the missing values (part iii)\n","**(Manejo de los valores perdidos (parte iii))**\n","<p> Nos hemos ocupado con éxito de los valores faltantes presentes en las columnas numéricas. Todavía hay algunos valores faltantes para imputar para las columnas 0, 1, 3, 4, 5, 6 y 13. Todas estas columnas contienen datos no numéricos y por eso la estrategia de imputación media no funcionaría aquí. Esto necesita un tratamiento diferente. </p>\n","<p> Vamos a imputar estos valores perdidos con los valores más frecuentes presentes en las columnas respectivas. Esta es una <a href=\"https://www.datacamp.com/community/tutorials/categorical-data\"> buena práctica </a> cuando se trata de imputar valores faltantes para datos categóricos en general. </p>"]},{"cell_type":"code","metadata":{"dc":{"key":"31"},"tags":["sample_code"],"collapsed":true,"trusted":false,"id":"yEX4z_89kYaf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633660304145,"user_tz":300,"elapsed":7,"user":{"displayName":"heydy carrasco huaccha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGyezGgm9Px4LBw_sc7MFWfjUVhWWsvnAz1Ttg=s64","userId":"00007591481982700116"}},"outputId":"272a3c7d-108b-4e7a-fe0e-ba5d62d69b80"},"source":["# Iterar sobre cada columna de cc_apps\n","for col in cc_apps:\n","    # Compruebe si la columna es de tipo de objeto\n","    if cc_apps[col].dtypes == 'object':\n","        # Imputar con el valor más frecuente\n","        cc_apps = cc_apps.fillna(cc_apps[col].value_counts().index[0])\n","\n","# Cuente el número de NaN en el conjunto de datos e imprima los recuentos para verificar\n","print(cc_apps.isnull().sum())"],"execution_count":103,"outputs":[{"output_type":"stream","name":"stdout","text":["0     0\n","1     0\n","2     0\n","3     0\n","4     0\n","5     0\n","6     0\n","7     0\n","8     0\n","9     0\n","10    0\n","11    0\n","12    0\n","13    0\n","14    0\n","15    0\n","dtype: int64\n"]}]},{"cell_type":"markdown","metadata":{"dc":{"key":"38"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"],"id":"4tTlxLcHkYag"},"source":["## 6. Preprocessing the data (part i)\n","**(Procesamiento previo de los datos (parte i))**\n","<p> Los valores faltantes ahora se gestionan correctamente. </p>\n","<p> Todavía se necesita un preprocesamiento de datos menor pero esencial antes de continuar con la construcción de nuestro modelo de aprendizaje automático. Vamos a dividir estos pasos restantes de preprocesamiento en tres tareas principales: </p>\n","<ol>\n","<li> Convierta los datos no numéricos en numéricos. </li>\n","<li> Divida los datos en conjuntos de prueba y de tren. </li>\n","<li> Escale los valores de las funciones a un rango uniforme. </li>\n","</ol>\n","<p> Primero, convertiremos todos los valores no numéricos en valores numéricos. Hacemos esto porque no solo da como resultado un cálculo más rápido, sino que también muchos modelos de aprendizaje automático (como XGBoost) (y especialmente los desarrollados con scikit-learn) requieren que los datos estén en un formato estrictamente numérico. Haremos esto usando una técnica llamada <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\"> codificación de etiquetas (label encoding.)</a>. </p>"]},{"cell_type":"code","metadata":{"dc":{"key":"38"},"tags":["sample_code"],"collapsed":true,"trusted":false,"id":"UBCYl-RWkYag","executionInfo":{"status":"ok","timestamp":1633660304145,"user_tz":300,"elapsed":6,"user":{"displayName":"heydy carrasco huaccha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGyezGgm9Px4LBw_sc7MFWfjUVhWWsvnAz1Ttg=s64","userId":"00007591481982700116"}}},"source":["# Importar LabelEncoder\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Crear una instancia de LabelEncoder\n","le=LabelEncoder()\n","\n","# Itere todos los valores de cada columna y extraiga sus dtypes\n","for col in cc_apps:\n","    # Compare si el dtype es un objeto\n","    if cc_apps[col].dtype == 'object':\n","    # Use LabelEncoder para hacer la transformación numérica\n","        cc_apps[col]=le.fit_transform(cc_apps[col])"],"execution_count":104,"outputs":[]},{"cell_type":"markdown","metadata":{"dc":{"key":"45"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"],"id":"1iD26VTzkYag"},"source":["## 7. Splitting the dataset into train and test sets\n","**(Dividir el conjunto de datos en conjuntos de prueba y de tren)**\n","<p> Hemos convertido correctamente todos los valores no numéricos en valores numéricos. </p>\n","<p> Ahora, dividiremos nuestros datos en conjuntos de trenes y conjuntos de pruebas para preparar nuestros datos para dos fases diferentes del modelado de aprendizaje automático: entrenamiento y pruebas. Idealmente, no se debe usar ninguna información de los datos de prueba para escalar los datos de entrenamiento o se debe usar para dirigir el proceso de entrenamiento de un modelo de aprendizaje automático. Por lo tanto, primero dividimos los datos y luego aplicamos la escala. </p>\n","<p> Además, funciones como <code> DriversLicense </code> y <code> ZipCode </code> no son tan importantes como las otras funciones del conjunto de datos para predecir las aprobaciones de tarjetas de crédito. Deberíamos descartarlos para diseñar nuestro modelo de aprendizaje automático con el mejor conjunto de características. En la literatura sobre ciencia de datos, esto a menudo se denomina <em> selección de características </em>. </p>"]},{"cell_type":"code","metadata":{"dc":{"key":"45"},"tags":["sample_code"],"collapsed":true,"trusted":false,"id":"bqXqMwxpkYag","executionInfo":{"status":"ok","timestamp":1633660304145,"user_tz":300,"elapsed":6,"user":{"displayName":"heydy carrasco huaccha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGyezGgm9Px4LBw_sc7MFWfjUVhWWsvnAz1Ttg=s64","userId":"00007591481982700116"}}},"source":["# Importar train_test_split\n","from sklearn.model_selection import train_test_split\n","\n","# Elimine las características 11 y 13 y convierta el DataFrame en una matriz NumPy\n","cc_apps = cc_apps.drop([11,13], axis=1)\n","cc_apps = cc_apps.to_numpy()\n","\n","# Segregar características y etiquetas en variables separadas \n","X,y = cc_apps[:,0:12] , cc_apps[:,13]\n","\n","# Dividir en trenes y conjuntos de prueba\n","X_train, X_test, y_train, y_test = train_test_split(X,\n","                                y,\n","                                test_size=0.33,\n","                                random_state=42)"],"execution_count":105,"outputs":[]},{"cell_type":"markdown","metadata":{"dc":{"key":"52"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"],"id":"9G1qmaGvkYah"},"source":["## 8. Preprocessing the data (part ii)\n","**(Procesamiento previo de los datos (parte ii))**\n","<p> Los datos ahora se dividen en dos conjuntos separados: conjuntos de entrenamiento y de prueba, respectivamente. Solo nos queda un paso final de preprocesamiento de escalado antes de que podamos ajustar un modelo de aprendizaje automático a los datos. </p>\n","<p> Ahora, intentemos comprender qué significan estos valores escalados en el mundo real. Usemos <code> CreditScore </code> como ejemplo. El puntaje crediticio de una persona es su solvencia basada en su historial crediticio. Cuanto mayor sea este número, se considera que una persona es más confiable desde el punto de vista financiero. Por lo tanto, un <code> CreditScore </code> de 1 es el más alto, ya que estamos cambiando la escala de todos los valores al rango de 0-1. </p>"]},{"cell_type":"code","metadata":{"dc":{"key":"52"},"tags":["sample_code"],"collapsed":true,"trusted":false,"id":"Z7K2xG0BkYah","executionInfo":{"status":"ok","timestamp":1633660304146,"user_tz":300,"elapsed":7,"user":{"displayName":"heydy carrasco huaccha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGyezGgm9Px4LBw_sc7MFWfjUVhWWsvnAz1Ttg=s64","userId":"00007591481982700116"}}},"source":["# Importar MinMaxScaler \n","from sklearn.preprocessing import MinMaxScaler\n","\n","# Cree una instancia de MinMaxScaler \n","#   y úselo para cambiar la escala de X_train y X_test\n","scaler = MinMaxScaler(feature_range=(0,1))\n","rescaledX_train = scaler.fit_transform(X_train)\n","rescaledX_test = scaler.fit_transform(X_test)"],"execution_count":106,"outputs":[]},{"cell_type":"markdown","metadata":{"dc":{"key":"59"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"],"id":"s-9NgJ2FkYah"},"source":["## 9. Fitting a logistic regression model to the train set\n","**(Ajuste de un modelo de regresión logística al tren)**\n","<p> Básicamente, predecir si una solicitud de tarjeta de crédito será aprobada o no es una tarea de clasificación </a>.\n","\n","Según UCI, nuestro conjunto de datos contiene más instancias que corresponden a Estado \"Denegado\" que las instancias correspondientes al estado \"Aprobado\". Específicamente, de 690 casos, hay 383 (55,5%) aplicaciones que fueron denegadas y 307 (44,5%) aplicaciones que fueron aprobadas. </p>\n","<p> Esto nos da un punto de referencia. Un buen modelo de aprendizaje automático debería poder predecir con precisión el estado de las aplicaciones con respecto a estas estadísticas. </p>\n","<p> ¿Qué modelo deberíamos elegir? Una pregunta que debe hacerse es: <em> ¿las características que afectan el proceso de decisión de aprobación de la tarjeta de crédito están correlacionadas entre sí? </em> Aunque podemos medir la correlación, eso está fuera del alcance de este portátil, por lo que confiaremos en nuestra intuición de que de hecho están correlacionados por ahora. Debido a esta correlación, aprovecharemos el hecho de que los modelos lineales generalizados funcionan bien en estos casos. Comencemos nuestro modelado de aprendizaje automático con un modelo de regresión logística (un modelo lineal generalizado). </p>"]},{"cell_type":"code","metadata":{"dc":{"key":"59"},"tags":["sample_code"],"collapsed":true,"trusted":false,"id":"mPXUtE-QkYah","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633660304146,"user_tz":300,"elapsed":7,"user":{"displayName":"heydy carrasco huaccha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGyezGgm9Px4LBw_sc7MFWfjUVhWWsvnAz1Ttg=s64","userId":"00007591481982700116"}},"outputId":"0c45fd45-0ee9-48f3-e1dd-cd7cb940d3ff"},"source":["# Importamos LogisticRegression\n","from sklearn.linear_model import LogisticRegression\n","\n","# Cree una instancia de un clasificador LogisticRegression \n","#     con valores de parámetros predeterminados\n","logreg = LogisticRegression()\n","\n","# Fit logreg en train set\n","logreg.fit(rescaledX_train,y_train)"],"execution_count":107,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n","                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n","                   multi_class='auto', n_jobs=None, penalty='l2',\n","                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n","                   warm_start=False)"]},"metadata":{},"execution_count":107}]},{"cell_type":"markdown","metadata":{"dc":{"key":"66"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"],"id":"aDQWj12NkYai"},"source":["## 10. Making predictions and evaluating performance\n","**(Hacer predicciones y evaluar el desempeño)**\n","<p> Pero, ¿qué tan bien funciona nuestro modelo? </p>\n","<p> Ahora evaluaremos nuestro modelo en el conjunto de prueba con respecto a la <a href=\"https://developers.google.com/machine-learning/crash-course/classification/accuracy\"> precisión de clasificación </a> . Pero también echaremos un vistazo a la <a href=\"http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/\"> matriz de confusión </a> del modelo. En el caso de predecir aplicaciones de tarjetas de crédito, es igualmente importante ver si nuestro modelo de aprendizaje automático es capaz de predecir el estado de aprobación de las aplicaciones como denegadas que originalmente fueron denegadas. Si nuestro modelo no está funcionando bien en este aspecto, entonces podría terminar aprobando la aplicación que debería haber sido aprobada. La matriz de confusión nos ayuda a ver el desempeño de nuestro modelo desde estos aspectos. </p>"]},{"cell_type":"code","metadata":{"dc":{"key":"66"},"tags":["sample_code"],"collapsed":true,"trusted":false,"id":"KLfCSpB2kYai","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633660304146,"user_tz":300,"elapsed":5,"user":{"displayName":"heydy carrasco huaccha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGyezGgm9Px4LBw_sc7MFWfjUVhWWsvnAz1Ttg=s64","userId":"00007591481982700116"}},"outputId":"76fcff10-ec24-47fe-c1a2-dd39e02d5aba"},"source":["# Importar confusion_matrix\n","from sklearn.metrics import confusion_matrix\n","\n","# Use logreg para predecir instancias del conjunto de prueba y almacenarlo\n","y_pred = logreg.predict(rescaledX_test)\n","\n","# Obtenga la puntuación de precisión del modelo logreg e imprímalo\n","print(\"Accuracy of logistic regression classifier: \", logreg.score(rescaledX_test,y_test))\n","\n","# Imprima la matriz de confusión del modelo logreg\n","print(confusion_matrix(y_test,y_pred))"],"execution_count":108,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of logistic regression classifier:  0.8377192982456141\n","[[93 10]\n"," [27 98]]\n"]}]},{"cell_type":"markdown","metadata":{"dc":{"key":"73"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"],"id":"kAX_6lmskYai"},"source":["## 11. Grid searching and making the model perform better\n","**(Búsqueda de cuadrícula y mejora del rendimiento del modelo)**\n","<p> ¡Nuestro modelo era bastante bueno! Pudo producir una puntuación de precisión de casi el 84%. </p>\n","<p> Para la matriz de confusión, el primer elemento de la primera fila de la matriz de confusión denota los verdaderos negativos, es decir, el número de instancias negativas (aplicaciones denegadas) predichas correctamente por el modelo. Y el último elemento de la segunda fila de la matriz de confusión denota los verdaderos positivos, es decir, el número de instancias positivas (aplicaciones aprobadas) predichas correctamente por el modelo. </p>\n","<p> Veamos si podemos hacerlo mejor. Podemos realizar una <a href=\"https://machinelearningmastery.com/how-to-tune-algorithm-parameters-with-scikit-learn/\"> búsqueda de cuadrícula </a> de los parámetros del modelo para mejorar la capacidad del modelo para predecir las aprobaciones de tarjetas de crédito. </p>\n","<p> <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\"> la implementación de scikit-learn de regresión logística </a> consta de diferentes hiperparámetros, pero nosotros buscará en cuadrícula los dos siguientes: </p>\n","<ul>\n","<li> tol </li>\n","<li> max_iter </li>\n","</ul>"]},{"cell_type":"code","metadata":{"dc":{"key":"73"},"tags":["sample_code"],"collapsed":true,"trusted":false,"id":"SyKSG2JwkYai","executionInfo":{"status":"ok","timestamp":1633660304360,"user_tz":300,"elapsed":2,"user":{"displayName":"heydy carrasco huaccha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGyezGgm9Px4LBw_sc7MFWfjUVhWWsvnAz1Ttg=s64","userId":"00007591481982700116"}}},"source":["# Importar GridSearchCV\n","from sklearn.model_selection import GridSearchCV\n","\n","# Definir la cuadrícula de valores para tol y max_iter\n","tol = [0.01, 0.001 ,0.0001]\n","max_iter = [100,150,200]\n","\n","# Cree un diccionario donde tol y max_iter son claves y \n","#     las listas de sus valores son valores correspondientes\n","param_grid = dict(tol=tol, max_iter=max_iter)"],"execution_count":109,"outputs":[]},{"cell_type":"markdown","metadata":{"dc":{"key":"80"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"],"id":"gAwGc8S4kYai"},"source":["## 12. Finding the best performing model\n","**(Encontrar el modelo con mejor rendimiento)**\n","<p> Hemos definido la cuadrícula de valores de hiperparámetros y los hemos convertido en un formato de diccionario único que <code> GridSearchCV () </code> espera como uno de sus parámetros. Ahora, comenzaremos la búsqueda en la cuadrícula para ver qué valores funcionan mejor. </p>\n","<p> Crearemos una instancia de <code> GridSearchCV () </code> con nuestro modelo anterior <code> logreg </code> con todos los datos que tenemos. En lugar de pasar el tren y los conjuntos de prueba por separado, proporcionaremos <code> X </code> (versión escalada) e <code> y </code>. También le indicaremos a <code> GridSearchCV () </code> que realice una <a href=\"https://www.dataschool.io/machine-learning-with-scikit-learn/\"> validación cruzada </a> de cinco pliegues. </p>\n","\n","<p> Finalizaremos el cuaderno almacenando la puntuación mejor obtenida y los mejores parámetros respectivos. </p>\n","<p> Al crear este predictor de tarjetas de crédito, abordamos algunos de los pasos de preprocesamiento más conocidos, como <strong> escalado </strong>, <strong> codificación de etiquetas </strong> y <strong> imputación de valor faltante </strong>. Terminamos con algo de <strong> aprendizaje automático </strong> para predecir si la solicitud de una persona para una tarjeta de crédito se aprobaría o no se proporcionaría información sobre esa persona. </p>"]},{"cell_type":"code","metadata":{"dc":{"key":"80"},"tags":["sample_code"],"collapsed":true,"trusted":false,"id":"F3eOsVEekYaj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633660304736,"user_tz":300,"elapsed":378,"user":{"displayName":"heydy carrasco huaccha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGyezGgm9Px4LBw_sc7MFWfjUVhWWsvnAz1Ttg=s64","userId":"00007591481982700116"}},"outputId":"dce204c4-7a38-4933-fa10-dc50502015d3"},"source":["# Cree una instancia de GridSearchCV con los parámetros requeridos\n","grid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)\n","\n","# Utilice scaler para cambiar la escala de X y asignarlo a rescaledX\n","rescaledX = scaler.fit_transform(X)\n","\n","# Fit data a grid_model\n","grid_model_result = grid_model.fit(rescaledX, y)\n","\n","# Summarize resultados\n","best_score, best_params = grid_model_result.best_score_ , grid_model_result.best_params_\n","print(\"Best: %f using %s\" % (best_score, best_params))"],"execution_count":110,"outputs":[{"output_type":"stream","name":"stdout","text":["Best: 0.850725 using {'max_iter': 100, 'tol': 0.01}\n"]}]}]}